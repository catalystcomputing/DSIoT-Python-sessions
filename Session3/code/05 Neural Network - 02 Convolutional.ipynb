{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. The Convolutional Neural Network (CNN) architecture\n",
    "\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Our Multi-Layer Perceptron (MLP) works quite well on the MNIST dataset. What need is there for a new architecture ?\n",
    "\n",
    "The problem with the MLP is that it does not take the image structure into account. Indeed, the input data, an array with 784 entries, could very well be shuffled (entry 0 becomes entry 26, entry 26 becomes entry 54 and so on), it would not matter to the MLP (try it !).\n",
    "\n",
    "This means that the two images below are essentially the same for our neural network!  \n",
    "(Going from left to right, we applied a random permutation of the grayscale values of this MNIST image).\n",
    "![Randshuf](Figures/rand_shuffle.png)\n",
    "\n",
    "Clearly, our architecture is a waste of information. In addition, it is computationally expensive as our network is fully connected : for the MNIST dataset, it is still feasible, but for higher resolution images, learning all the weights and biases quickly becomes prohibitive.\n",
    "\n",
    "We will now see how a cleverer architecture can be used to efficiently tackle image classification.\n",
    "\n",
    "\n",
    "## Architecture\n",
    "\n",
    "#### Restrict connections\n",
    "A simple solution to the computation cost is to restrict connections between units. We will now connect each unit in the hidden layer to a small patch of contiguous pixels from the input image.\n",
    "\n",
    "This is in close analogy to the way visual systems work: neurons in the visual cortex have localized receptive fields and will only respond to stimuli from a given location.\n",
    "\n",
    "#### Use shared weights\n",
    "We will also make use of shared weights. By shared weights, we mean that we apply the same transformation for all subpatch of the input image. This ensures that every unit in the hidden layer detects exactly the same pattern, albeit at different locations of the input image.\n",
    "\n",
    "This design choice is desirable because natural images have the property of being ”‘stationary”’. For instance, if we find an operation that allows us to detect a stick in one part of the image, we should be able to detect a stick elsewhere by applying the same operation to other patches of the image. \n",
    "\n",
    "Shared weights also immediately decrease the number of parameters to be learnt and thus the computational cost.\n",
    "\n",
    "The way Convolutional Networks operate is best explained visually :\n",
    "\n",
    "![Conv_schem](Figures/Convolution_schematic.gif)\n",
    "\n",
    "In the GIF above, the green array is an 8x8 schematic input image, with cells indicating pixels and cell values indicating color intensity. The pink array is a 3x3 hidden layer.\n",
    "\n",
    "Each unit in the hidden layer is connected to a patch of the input image (the sliding 3x3 orange window). The values in each cell of the hidden layers are computed with the same operation (i.e. the weights of the sliding orange window do not change).\n",
    "\n",
    "For instance, the first unit of the hidden layer is connected to the following patch of the input image:\n",
    "\n",
    "$$P=\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    0 & 1 & 1 \\\\\n",
    "    0 & 0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "To compute the value of the first unit of the hidden layer, we do :\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\rm value=\\rm Sum(P\\odot W)&= 1\\times 1 + 1\\times 0 +1\\times 1 \\\\\n",
    "&+ 0\\times 0 + 1\\times 1 + 1\\times 0 \\\\\n",
    "&+ 0\\times 1 + 0\\times 0 + 1\\times 1 \\\\\n",
    "& = 4\n",
    "\\tag{1}\\end{eqnarray}\n",
    "\n",
    "where W, the weight matrix is defined as:\n",
    "\n",
    "$$W=\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 1 \\\\\n",
    "    0 & 1 & 0 \\\\\n",
    "    1 & 0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Of course, we won't restrict ourselves to a single weight matrix (also called kernel or filter matrix). Indeed, we don't want to restrict ourselves to sticks only, we may be interested in detecting stars or ellipses. This is why we will use several weight matrices at this stage, as shown on the image below :\n",
    "\n",
    "![Several](Figures/tikz46.png)\n",
    "\n",
    "In this example, we apply 3 different 5x5 weight matrices to the input MNIST data, obtaining convolved features of size 3 x (28-5+1) * (28-5+1) \n",
    "\n",
    "As an aside, note that the operation Eq. (1) is a form of convolution hence the name of the architecture.\n",
    "\n",
    "#### Pooling\n",
    "\n",
    "It is possible to use all the features in the hidden layer. However, this can lead to computational issues.\n",
    "Let us give an illustratory example :\n",
    "\n",
    "- Assume images of 96 x 96 pixels\n",
    "- We use an 8 x 8 sliding window \n",
    "- This gives 7921 units in the hidden layer\n",
    "- If we assume we have 400 weight matrices, this yields a vector of 7921*400 = 3,168,400\n",
    "- This large feature vector is clearly unwieldy !\n",
    "\n",
    "To address this, we condense the information with a so-called pooling layer. For instance, we could take the mean of neighboring cells in the hidden layer and obtain a much lower dimension feature vector.\n",
    "\n",
    "This operation can greatly reduce the computational burden and also address overfitting issues.\n",
    "The figure below shows how this works in practice :\n",
    "\n",
    "![Pool_schem](Figures/Pooling_schematic.gif)\n",
    "\n",
    "The hidden layer units are divided into 4 groups (highlighted by the sliding red window). Then we take the mean (or the max, or whatever summary statistics we choose) of each group. This yields a much lower dimension vector.\n",
    "\n",
    "#### Full architecture\n",
    "\n",
    "Combining all that we've seen above, we get the following architecture :\n",
    "\n",
    "![Full_arch](Figures/tikz49.png)\n",
    "\n",
    "- Input layer (the 28 x 28 MNIST image)\n",
    "- Hidden layer of dimension 3 x 24 x 24 (obtained with 3 filter matrices and a 5 x 5  sliding window)\n",
    "- A pooling layer of dimension 3 x 12 x12 (obtained after taking the max in 2 x 2 windows of the hidden layer)\n",
    "- The final layer is a fully connected layer which connects all pooled feature to the 10 output units\n",
    "\n",
    "**N.B.** The size of the convolution filter (5x5 in this example) is a hyperparameter, as well as the stride length (which states by how many pixels we slide the window). They can and should be tuned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Theano\n",
    "\n",
    "We will now use Theano to build our neural network.\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "From Wikipedia :\n",
    "\n",
    "> Theano is a numerical computation library for Python. In Theano, computations are expressed using a NumPy-like syntax and compiled to run efficiently on either CPU or GPU architectures.\n",
    "\n",
    "In case you do have a GPU on your machine, Theano can greatly speed up computations for Deep Neural Networks.\n",
    "In case you don't, you can run a GPU instance on the [Amazon Web Services](https://aws.amazon.com/)\n",
    "\n",
    "\n",
    "## Installation\n",
    "An easy way to install theano and its dependencies is to use the\n",
    "Anaconda package by continuum analytics.\n",
    "\n",
    "To do so, we download the latest package from the Anaconda website.\n",
    "For Linux and to this date (January 2016), the command is :\n",
    "\n",
    "    wget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.1-Linux-x86_64.sh\n",
    "\n",
    "Then in the directory were it was downloaded :\n",
    "\n",
    "    bash Anaconda2-2.4.1-Linux-x86_64.sh\n",
    "\n",
    "Or\n",
    "\n",
    "## Install\n",
    "\n",
    "http://docs.continuum.io/anaconda/install\n",
    "\n",
    "### Update to latest version\n",
    "\n",
    "`conda update conda`\n",
    "\n",
    "`conda update ipython ipython-notebook ipython-qtconsole`\n",
    "\n",
    "`pip install Theano`\n",
    "\n",
    "You should now be able to use Theano with python.\n",
    "All the code below can be ran without a GPU.\n",
    "However, activating the GPU may greatly speed up the examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This program makes use of the Theano library to speed up computations.\n",
    "\n",
    "Besides speeding up computations through the use of a GPU,\n",
    "Theano also automatically computes the mappings required for the\n",
    "backpropagation algorithm\n",
    "\n",
    "This program also implements dropout \n",
    "(a method in which you randomly deactivate some units inside the neural network)\n",
    "this helps regularisation and performance\n",
    "But you should pay it no heed in this tutorial\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#### Libraries\n",
    "# Standard library\n",
    "import cPickle\n",
    "import gzip\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "from theano.tensor.nnet import softmax\n",
    "from theano.tensor import shared_randomstreams\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "# Activation functions for neurons\n",
    "from theano.tensor.nnet import sigmoid\n",
    "from theano.tensor import tanh\n",
    "\n",
    "\n",
    "#### Constants\n",
    "GPU = False\n",
    "if GPU:\n",
    "    print \"Running under a GPU\"\n",
    "    try: theano.config.device = 'gpu'\n",
    "    except: pass # it's already set\n",
    "    theano.config.floatX = 'float32'\n",
    "else:\n",
    "    print \"Running with a CPU\"\n",
    "\n",
    "#### Load the MNIST data\n",
    "def load_data_shared(filename=\"../data/mnist.pkl.gz\"):\n",
    "    f = gzip.open(filename, 'rb')\n",
    "    training_data, validation_data, test_data = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "    # We store the data in so-called shared-variables\n",
    "    #The reason we store our dataset in shared variables is to allow\n",
    "    #Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    #Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    #is needed (the default behaviour if the data is not in a shared\n",
    "    #variable) would lead to a large decrease in performance.\n",
    "    def shared(data):\n",
    "        \"\"\"Place the data into shared variables.  This allows Theano to copy\n",
    "        the data to the GPU, if one is available.\n",
    "\n",
    "        \"\"\"\n",
    "        shared_x = theano.shared(\n",
    "            np.asarray(data[0], dtype=theano.config.floatX), borrow=True)\n",
    "        shared_y = theano.shared(\n",
    "            np.asarray(data[1], dtype=theano.config.floatX), borrow=True)\n",
    "        return shared_x, T.cast(shared_y, \"int32\")\n",
    "    return [shared(training_data), shared(validation_data), shared(test_data)]\n",
    "\n",
    "#### Main class used to construct and train networks\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, layers, mini_batch_size):\n",
    "        \"\"\"Takes a list of `layers`, describing the network architecture, and\n",
    "        a value for the `mini_batch_size` to be used during training\n",
    "        by stochastic gradient descent.\n",
    "\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.params = [param for layer in self.layers for param in layer.params]\n",
    "        # Theano symbolic variables\n",
    "        self.x = T.matrix(\"x\")\n",
    "        self.y = T.ivector(\"y\")\n",
    "        init_layer = self.layers[0]\n",
    "        init_layer.set_inpt(self.x, self.x, self.mini_batch_size)\n",
    "        for j in xrange(1, len(self.layers)):\n",
    "            prev_layer, layer  = self.layers[j-1], self.layers[j]\n",
    "            layer.set_inpt(\n",
    "                prev_layer.output, prev_layer.output_dropout, self.mini_batch_size)\n",
    "        self.output = self.layers[-1].output\n",
    "        self.output_dropout = self.layers[-1].output_dropout\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            validation_data, test_data, lmbda=0.0):\n",
    "        \"\"\"Train the network using mini-batch stochastic gradient descent.\"\"\"\n",
    "        training_x, training_y = training_data\n",
    "        validation_x, validation_y = validation_data\n",
    "        test_x, test_y = test_data\n",
    "\n",
    "        # compute number of minibatches for training, validation and testing\n",
    "        num_training_batches = size(training_data)/mini_batch_size\n",
    "        num_validation_batches = size(validation_data)/mini_batch_size\n",
    "        num_test_batches = size(test_data)/mini_batch_size\n",
    "\n",
    "        # define the (regularized) cost function, symbolic gradients, and updates\n",
    "        l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers])\n",
    "        # set up the (regularised) log likelihood function\n",
    "        cost = self.layers[-1].cost(self)+\\\n",
    "               0.5*lmbda*l2_norm_squared/num_training_batches\n",
    "        # compute the gradient of our cost function\n",
    "        grads = T.grad(cost, self.params)\n",
    "        updates = [(param, param-eta*grad)\n",
    "                   for param, grad in zip(self.params, grads)]\n",
    "\n",
    "        # define functions to train a mini-batch, and to compute the\n",
    "        # accuracy in validation and test mini-batches.\n",
    "        i = T.lscalar() # mini-batch index\n",
    "        #train_mb is a symbolic theano function\n",
    "        train_mb = theano.function(\n",
    "            [i], cost, updates=updates,\n",
    "            givens={\n",
    "                self.x:\n",
    "                training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        validate_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        test_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        self.test_mb_predictions = theano.function(\n",
    "            [i], self.layers[-1].y_out,\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        # Do the actual training\n",
    "        best_validation_accuracy = 0.0\n",
    "        for epoch in xrange(epochs):\n",
    "            for minibatch_index in xrange(num_training_batches):\n",
    "                iteration = num_training_batches*epoch+minibatch_index\n",
    "                if iteration % 1000 == 0:\n",
    "                    print(\"Training mini-batch number {0}\".format(iteration))\n",
    "                cost_ij = train_mb(minibatch_index)\n",
    "                if (iteration+1) % num_training_batches == 0:\n",
    "                    validation_accuracy = np.mean(\n",
    "                        [validate_mb_accuracy(j) for j in xrange(num_validation_batches)])\n",
    "                    print(\"Epoch {0}: validation accuracy {1:.2%}\".format(\n",
    "                        epoch, validation_accuracy))\n",
    "                    if validation_accuracy >= best_validation_accuracy:\n",
    "                        print(\"This is the best validation accuracy to date.\")\n",
    "                        best_validation_accuracy = validation_accuracy\n",
    "                        best_iteration = iteration\n",
    "                        if test_data:\n",
    "                            test_accuracy = np.mean(\n",
    "                                [test_mb_accuracy(j) for j in xrange(num_test_batches)])\n",
    "                            print('The corresponding test accuracy is {0:.2%}'.format(\n",
    "                                test_accuracy))\n",
    "        print(\"Finished training network.\")\n",
    "        print(\"Best validation accuracy of {0:.2%} obtained at iteration {1}\".format(\n",
    "            best_validation_accuracy, best_iteration))\n",
    "        print(\"Corresponding test accuracy of {0:.2%}\".format(test_accuracy))\n",
    "\n",
    "#### Define layer types\n",
    "\n",
    "class ConvPoolLayer(object):\n",
    "    \"\"\"Used to create a combination of a convolutional and a max-pooling\n",
    "    layer.  A more sophisticated implementation would separate the\n",
    "    two, but for our purposes we'll always use them together, and it\n",
    "    simplifies the code, so it makes sense to combine them.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filter_shape, image_shape, poolsize=(2, 2),\n",
    "                 activation_fn=sigmoid):\n",
    "        \"\"\"`filter_shape` is a tuple of length 4, whose entries are the number\n",
    "        of filters, the number of input feature maps, the filter height, and the\n",
    "        filter width.\n",
    "\n",
    "        `image_shape` is a tuple of length 4, whose entries are the\n",
    "        mini-batch size, the number of input feature maps, the image\n",
    "        height, and the image width.\n",
    "\n",
    "        `poolsize` is a tuple of length 2, whose entries are the y and\n",
    "        x pooling sizes.\n",
    "\n",
    "        \"\"\"\n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.poolsize = poolsize\n",
    "        self.activation_fn=activation_fn\n",
    "        # initialize weights and biases\n",
    "        n_out = (filter_shape[0]*np.prod(filter_shape[2:])/np.prod(poolsize))\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=np.sqrt(1.0/n_out), size=filter_shape),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=1.0, size=(filter_shape[0],)),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape(self.image_shape)\n",
    "        conv_out = conv.conv2d(\n",
    "            input=self.inpt, filters=self.w, filter_shape=self.filter_shape,\n",
    "            image_shape=self.image_shape)\n",
    "        pooled_out = downsample.max_pool_2d(\n",
    "            input=conv_out, ds=self.poolsize, ignore_border=True)\n",
    "        self.output = self.activation_fn(\n",
    "            pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "        self.output_dropout = self.output # no dropout in the convolutional layers\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class FullyConnectedLayer(object):\n",
    "\n",
    "    def __init__(self, n_in, n_out, activation_fn=sigmoid, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.activation_fn = activation_fn\n",
    "        self.p_dropout = p_dropout\n",
    "        # Initialize weights and biases\n",
    "        # use gaussian with proper width to initialise\n",
    "        # we use shared variables to limit computation overhead\n",
    "        # between CPU and GPU\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)),\n",
    "                dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)),\n",
    "                       dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = self.activation_fn(\n",
    "            (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = self.activation_fn(\n",
    "            T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        \"Return the accuracy for the mini-batch.\"\n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "class SoftmaxLayer(object):\n",
    "\n",
    "    def __init__(self, n_in, n_out, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.p_dropout = p_dropout\n",
    "        # Initialize weights and biases\n",
    "        self.w = theano.shared(\n",
    "            np.zeros((n_in, n_out), dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.zeros((n_out,), dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = softmax((1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def cost(self, net):\n",
    "        \"Return the log-likelihood cost.\"\n",
    "        return -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y])\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        \"Return the accuracy for the mini-batch.\"\n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "\n",
    "#### Miscellanea\n",
    "def size(data):\n",
    "    \"Return the size of the dataset `data`.\"\n",
    "    return data[0].get_value(borrow=True).shape[0]\n",
    "\n",
    "def dropout_layer(layer, p_dropout):\n",
    "    srng = shared_randomstreams.RandomStreams(\n",
    "        np.random.RandomState(0).randint(999999))\n",
    "    mask = srng.binomial(n=1, p=1-p_dropout, size=layer.shape)\n",
    "    return layer*T.cast(mask, theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Application example\n",
    "\n",
    "### Multi layer perceptron benchmark\n",
    "\n",
    "- An input layer\n",
    "- One hidden layer\n",
    "- A softmax output layer\n",
    "- The learning rate $\\eta$ is set to 0.1, the mini batch size to 10 and we train for 60 epochs.\n",
    "\n",
    "The accuracy should reach somewhere close to 97.8 % at best.\n",
    "\n",
    "**N.B** It takes some time to complete the full training, feel free to stop anytime.\n",
    "**N.B.** If you have a GPU, feel free to activate it (set the GPU flag to True in the code), it should speed up computations !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        FullyConnectedLayer(n_in=784, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching to a CNN\n",
    "\n",
    "- An input layer\n",
    "- One convolution layer (20 5 x 5 weight matrices\n",
    "- One pooled layer (takes the max in a 2x2 window of the convolution layer)\n",
    "- One fully connected (100 sigmoid units) layer\n",
    "- One softmax layer\n",
    "- The learning rate $\\eta$ is set to 0.1, the mini batch size to 10 and we train for 60 epochs.\n",
    "\n",
    "![simple_conv](Figures/simple_conv.png)\n",
    "\n",
    "The accuracy should reach somewhere close to 98.8 % at best. While it does not seem much of an improvement, it actually means a 45% decrease in the error rate over the previous network !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 94.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.80%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.43%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.16%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.31%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.09%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 97.67%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.55%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 97.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.87%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.19%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.99%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.30%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.15%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.34%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.23%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.43%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.28%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-0720f25255d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n\u001b[1;32m      7\u001b[0m net.SGD(training_data, 60, mini_batch_size, 0.1, \n\u001b[0;32m----> 8\u001b[0;31m             validation_data, test_data) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-030f307c9bf9>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training mini-batch number {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mcost_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     validation_accuracy = np.mean(\n",
      "\u001b[0;32m/home/tmain/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tmain/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tmain/anaconda/lib/python2.7/site-packages/theano/tensor/raw_random.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, out_)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mrout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                \u001b[0;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix : producing the MNIST image and the shuffled version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,) (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Let's start by importing relevant packages :\n",
    "import cPickle as pickle\n",
    "import subprocess\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Define a function to unzip the mnist data and load it\n",
    "def get_mnist_data():\n",
    "    \"\"\" Unzip mnist data if needed and load it\"\"\"\n",
    "    if not os.path.isfile(\"./Data/mnist.pkl\"):\n",
    "        subprocess.call(\"gunzip -k ./Data/mnist.pkl.gz\".split(\" \"))\n",
    "    with open(\"./Data/mnist.pkl\", \"r\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "p = get_mnist_data()\n",
    "print p[0][0][0].shape, p[0][1].shape\n",
    "im, num =  p[0][0][0], p[0][1][0]\n",
    "im = np.reshape(im, (28,28))\n",
    "imr = im.copy()\n",
    "# Shuffle a copy of the image\n",
    "np.random.shuffle(imr)\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = GridSpec(1, 2, bottom=0.18, left=0.18, right=0.88)\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "axshuff = fig.add_subplot(gs[1])\n",
    "\n",
    "#Plot the first MNIST image in the data and its \n",
    "# shuffled version side by side.\n",
    "image = ax.imshow(im, cmap=mpl.cm.Greys)\n",
    "imageshuff = axshuff.imshow(imr, cmap=mpl.cm.Greys)\n",
    "imageshuff.set_interpolation('nearest')\n",
    "image.set_interpolation('nearest')\n",
    "\n",
    "plt.savefig(\"Figures/rand_shuffle.png\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures courtesy of Matt Nielsen and Stanford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
